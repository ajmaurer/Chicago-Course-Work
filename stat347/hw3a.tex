
\documentclass[11pt]{article}
\usepackage[paper=letterpaper, margin=.5in]{geometry}
\pdfpagewidth 8.5in
\pdfpageheight 11in
\setlength\parindent{0in}

%%% Packages
% First four - AMS (american mathematical society). General math goodness. I use the align* enviorment in particular
% multirow, multicol allow for certain kinds of tables
% enumerate lets you determine the style of the counter for the enumerate enviorment
% graphicx lets you include pictures
% listings lets you stick in blocks of code
% placeins defines "\FloatBarrier", which stops tables from moving around
\usepackage{amsmath, amscd, amssymb, amsthm, multirow, multicol, enumerate, graphicx, listings, placeins} 
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\C}{\mathbb{C}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\V}{\mathbb{V}}
\newcommand{\U}{\mathcal{U}}
\newcommand{\del}{\partial}
\newcommand{\real}{\textrm{Re }}
\newcommand{\imag}{\textrm{Im }}
\newcommand{\pd}[2]{\frac{\partial #1}{\partial #2}}
\newcommand{\deriv}[2]{\frac{d #1}{d #2}}
\newcommand{\sumk}{\sum_{k=1}^\infty}
\newcommand{\sumj}{\sum_{j=1}^\infty}
\newcommand{\sumn}{\sum_{n=0}^\infty}
\newcommand{\summ}[2]{\sum_{k=#1}^{#2}}
\newcommand{\sig}[1]{\sum_{#1 =1}^\infty}
\newcommand{\un}[1]{\bigcup_{#1 =1}^\infty}
\newcommand{\inter}[1]{\bigcap_{#1 =1}^\infty}
\newcommand{\ip}[2]{\langle #1, #2 \rangle}
\newcommand{\ipxu}{\langle x,u_j \rangle}
\newcommand{\uj}{\{u_j\}_{j=1}^\infty}
\newcommand{\B}{\mathcal{B}}

\newcommand{\p}{\mathrm{P}}
\newcommand{\E}{\mathrm{E}}
\newcommand{\var}{\mathrm{Var}}
\newcommand{\cov}{\mathrm{Cov}}
\newcommand{\ST}{mbox{ s.t. }}

\newcommand{\Example}{\noindent {\bf Example. \quad} }
\newcommand{\Proof}{\noindent {\bf Proof: \quad} }
\newcommand{\Remark}{\noindent {\bf Remark. \quad} }
\newcommand{\Remarks}{\noindent {\bf Remarks. \quad} }
\newcommand{\Case}{\noindent {\underline{Case} \quad} }

\newcommand{\st}{ \; \big | \:}

\newcommand{\deuc}{d_{\mathrm euc}}
\newcommand{\dtaxi}{d_{\mathrm taxi}}
\newcommand{\ddisc}{d_{\mathrm disc}}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{corollary}[theorem]{Corollary}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{example}[theorem]{Example}

\newcommand{\hwhead}[1]{#1 \hfill Aaron Maurer \vspace{2mm} \hrule \vspace{2mm}}

\begin{document}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\hwhead{STAT 347 Homework 3, Part 1}
\begin{itemize}
    \item[0.]
        \begin{itemize}
            \item[(i)]
                We can calculate the joint distribution easily from the description:
                \[\p(Y,N) = \begin{cases} 
                              \;            \frac{1}{3} &\mbox{if } Y=0,N=0 \\
                              \;   \frac{1}{3}(1-\pi_1) &\mbox{if } Y=0,N=1 \\
                              \;       \frac{1}{3}\pi_1 &\mbox{if } Y=1,N=1 \\
                              \;   \frac{1}{3}(1-\pi_2) &\mbox{if } Y=0,N=2 \\
                              \;       \frac{1}{3}\pi_2 &\mbox{if } Y=2,N=2 \\
                              \;            0           &\mbox{otherwise } \\
                            \end{cases} \]
            \item[(ii)]
                $Y/N \st N=1$ and $Y/N \st N=2$ are both Bernoulli random variables with probability with probabilities $\pi_1$, $\pi_2$, so 
                \[\E(Y/N \st N=1) = \pi_1,\; \var(Y/N \st N=1) = \pi_1(1-\pi_1),\;\E(Y/N \st N=2) = \pi_2,\; \var(Y/N \st N=1) = \pi_2(1-\pi_2) \]
                If $\pi_1=\pi_2$, $Y/N \st N=1 \sim Y/N \st N=2$, so $Y/N$ and $N$ are uncorrelated.
            \item[(iii)]
                Since the wells are independent, $Y\sim B(26,\pi_1)+2\times B(15,\pi_2)$, so
                \[ \E[Y] = \E[B(26,\pi_1)] + 2\E[B(15,\pi_2)] = 26\pi_1 + 30\pi_2\]
                and
                \[ \var(Y) = \var[B(26,\pi_1)] + 4 \var[B(15,\pi_2)] = 26\pi_1(1-\pi_1) + 60\pi_2(1-\pi_2)\]
            \item[(iv)]
                Fitting this distribution $F$ to the data, with $m=26\times1 + 15\times 2 = 56$, we would estimate 
                \[ \mu = m\pi = \E[Y] = 26\pi_1 + 30\pi_2 \Longrightarrow \pi = \frac{26\pi_1 + 30\pi_2}{56}\] 
                so we would calculate $\sigma^2$ as
                \begin{align*}
                    \sigma^2m\pi(1-\pi) &= \var[y] \\
                    \sigma^256\frac{26\pi_1 + 30\pi_2}{56}\left(1-\frac{26\pi_1 + 30\pi_2}{56}\right) &= 26\pi_1(1-\pi_1) + 60\pi_2(1-\pi_2)\\
                    \sigma^2&= \frac{56(26\pi_1(1-\pi_1) + 60\pi_2(1-\pi_2))}{(26\pi_1 + 30\pi_2)(56-26\pi_1 - 30\pi_2)}\\
                \end{align*}
                Which, in the case where $\pi_1=\pi_2=\pi$, reduces to 
                \[ \sigma^2 = \frac{76}{56} = \frac{19}{14}\]
            \item[(v)]
                Let $Y_1$ be the number of homogamic matings in single-mating wells out of $M_1$ total,  and $Y_2$ and $M_2$ the same for two mating wells. If we assume that $\pi_1=\pi_2=\pi$, then 
                \[ Y_2/2 \sim B(M_2/2,\pi) \quad \&\quad Y_1 \sim B(M_1,\pi)\]
                so 
                \[\var(Y_2) = \var(2B(M_2/2,\pi)) = 2M_2\pi(1-\pi)\]
                and 
                \[\var(Y_1) = \var(B(M_1,\pi)) = M_1\pi(1-\pi)\]
                so, if $2M_1=2M_2=M$,
                \begin{align*}
                    \var(Y) &= 2M_2\pi(1-\pi)+M_1\pi(1-\pi) \\
                    \sigma^2M\pi(1-\pi) &= \frac{3}{2}\pi(1-\pi) \\
                    \sigma^2 &= \frac{3}{2} \\
                \end{align*}
            \item[(vi)]
                This mechanism can't explain the chi-square test, which indicated under dispersion. If it was the case, as we simulated, that  homogamic and one heterogamic matings in the same well are impossible, then the result would be higher variance than the multinomial model anticipates. This is the opposite of what is observed in the actual data set, suggesting this mechanism is not the explanation.  
            \item[(vii)]
                They concluded that the data does not follow a multinomial distribution by looking at the variance of frequencies among replicated experiments, for instance through the same chi square test as above. Since these frequencies had much lower variance than one would anticipate with a multinomial model, they concluded the frequencies weren't multinomial. This would also stand to reason, since with only two flies of each gender in a well, one pair mating would necessarily effect the probability of the other pair mating, invalidating independence among the mating events. The data not being multinomial would invalidate the standard errors and p-values, which were made under an assumed multinomial mode.
            \item[(viii)] By only analyzing the first mating in each well, they were assuring there was no dependence among mating events they counted. Since there is independence between wells, this first mating must necessarily be independent of the other counted matings. With this fix, the multinomial model should hold again, allowing for simpler inference. 
            \item[(ix)]
                It appears counting just the first mating solves the dispersion problem. When performing a Chi-Square test for the presence of mating pair-generation effects, we now get a p-value of $.107$. If we then combine the counts for all homogamic and heterogamic matings in each generation and repeat the test, we get a p-value of .785. This suggests that we have the proper dispersion for a multinomial and that generations don't have an effect on mating preference. \vspace{2mm}
                
                If subsequent matings had been analyzed, aside from the mentioned statistical issues due to dependence, the conclusion would likely have been less well supported. First, we can imagine in general, the first mating to occur is in general the one representing the strongest preference. Even if this is not the case though, due to female flies refractory period, after one mating both male flies will likely attempt to mate with the remaining female fly. One can imagine that the desire to mate is stronger than a particular preference if there is only one option, making a preference harder to discern.
            \item[(x)]
                Testing the significance of homogamic versus heterogamic pairings, I ran a logistic regression on the counts:
                \FloatBarrier
                \input{hw3/A0_ix_logit}
                \FloatBarrier
                There is extremely high significance on the intercept, strongly supporting that the probability of the first mating being homogamic is high. This supports the authors' conclusion that homogamic prefernce is preferred, though one could imagine a case where preference changes after some exposure time and an initial mating. Also, I included a second degree polynomial on generation as a second test for whether it effected mating preference; as we can see, it does not.

        \end{itemize}
    \item[3.]
        \begin{itemize}
            \item[(a)]
                These are the parameter estimates from the main-effects linear logistic model:
                \FloatBarrier
                \input{hw3/A3_a_logit}
                \FloatBarrier
                For the deviance, the residual degrees of freedom are calculated as the observed unique combinations of predictors minus dimension of the linear space of predictors. Another way of saying this is the number of observations in the model after aggregating by predictors minus number of variable in the model (after removing linearly dependent variables). 
            \item[(b)]
                With an estimate of $.1239$ on sex2, the model is estimating a small increase in the rate of affected for women, though it is not statistically significant. We can estimate a confidence interval for the odds ratio by calculating a confidence interval for the parameter based on asymptotic normality and transforming it. To start, a $90\%$ CI for the parameter is:
                \[(.1239+z_{.05}.2288,1.239+z_{.95}.2288)\quad=\quad(-.2524,.5002)\]
                Then, we transform this by exponentiating it to yields an odds ratio CI:
                \[(e^{-.2524},e^{.5002})\quad=\quad (.7769,1.6491)\]
                Thus, we can say with $90\%$ confidence that the odds ratio for women as compared to men is between $.7769$ and $1.6491$.
            \item[(c)]
                I dropped sex first, and then race from the original model to get the model below. I didn't drop dust2 because thought it wasn't significant, it was part of a factor which was extremely significant.
                \FloatBarrier
                \input{hw3/A3_c_logit}
                \FloatBarrier
                Each of the remaining factors is estimated to cause a statistically significant increase in the risk of byssinosis. The third level of dust is estimated to cause a far bigger increase in risk than any of the other variables, causing a large increase over the first and second level, which are not statistically significantly different. The smoking level 2 and employment levels 2 and 3 both are estimated to increase the risk of the disease over the first level of each.
            \item[(d)]
                Of all the ten models, the only model with an interaction which was statistically significantly better by the likelihood ratio test (p-value of .02294) was the one with sex interacted with dust. After running that model, race remained insignificant, so was removed. This left the following model, in which there were no insignificant main effects which weren't part of the interaction:
                \FloatBarrier
                \input{hw3/A3_d_logit}
                \FloatBarrier
                The model now predicts that while dust level 3 still causes a big increase in risk over dust level 1, this increase in risk is much smaller for women. As well, the model now has the point estimate that dust 2 causes a small decrease in risk for men and a small increase in risk for women, though neither the main effect or interaction are statistically significant. Besides that, the predictions of the model by factor are largely similar to before, with every other variable causing a small increase in risk.
            \item[(e)]
                Based on the final version of the model, where sex and dust level are interacted, I have plotted the odds ratios for men and women at different dust levels below:
                \begin{center}
                    \includegraphics[width=12cm]{hw3/A3_e_plot} 
                \end{center}
                As you can see, the cotton dust level can greatly increase a workers risk of getting Byssinosis. When exposed to high levels, males are estimated to be 17.8 times more likely to get the disease then men exposed to low levels; women are 6.54 times as likely to get the disease than males at low levels. Though there are large error bounds on the risk for women, both men and women have statistically significantly increased risk. The big increase in risk seems to be predicated on high level exposure though. At medium levels, neither men or women are estimated to have significant increased in risk over men at low levels of dust, and there is not a statistically significant difference between men and women at the low level.
            \item[(f)]
                None of our inference for particular effects shows a statistically significant difference in risk of byssinosis by race and sex. However, we do see statistically significant improvement in the overall model when we include the interaction of sex and dust level. The significance wasn't so high as to preclude this improvement  being random, but this does suggest that gender has some effect on ones risk. The reason could well not be biological though; it could, for instance, be due to men and women being in different roles in the factory in a way not accounted for in our model. We don't however have any evidence that race is a factor, since neither the inclusion of it as a variable nor any interaction with it was meaningful.


        \end{itemize}
\end{itemize}

\end{document}
