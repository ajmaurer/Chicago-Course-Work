
\documentclass[11pt]{article}
\usepackage[paper=letterpaper, margin=.5in]{geometry}
\pdfpagewidth 8.5in
\pdfpageheight 11in
\setlength\parindent{0in}

%%% Packages
% First four - AMS (american mathematical society). General math goodness. I use the align* enviorment in particular
% multirow, multicol allow for certain kinds of tables
% enumerate lets you determine the style of the counter for the enumerate enviorment
% graphicx lets you include pictures
% listings lets you stick in blocks of code
% placeins defines "\FloatBarrier", which stops tables from moving around
\usepackage{amsmath, amscd, amssymb, amsthm, multirow, multicol, enumerate, graphicx, listings, placeins} 
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\C}{\mathbb{C}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\V}{\mathbb{V}}
\newcommand{\U}{\mathcal{U}}
\newcommand{\del}{\partial}
\newcommand{\real}{\textrm{Re }}
\newcommand{\imag}{\textrm{Im }}
\newcommand{\pd}[2]{\frac{\partial #1}{\partial #2}}
\newcommand{\deriv}[2]{\frac{d #1}{d #2}}
\newcommand{\sumk}{\sum_{k=1}^\infty}
\newcommand{\sumj}{\sum_{j=1}^\infty}
\newcommand{\sumn}{\sum_{n=0}^\infty}
\newcommand{\summ}[2]{\sum_{k=#1}^{#2}}
\newcommand{\sig}[1]{\sum_{#1 =1}^\infty}
\newcommand{\un}[1]{\bigcup_{#1 =1}^\infty}
\newcommand{\inter}[1]{\bigcap_{#1 =1}^\infty}
\newcommand{\ip}[2]{\langle #1, #2 \rangle}
\newcommand{\ipxu}{\langle x,u_j \rangle}
\newcommand{\uj}{\{u_j\}_{j=1}^\infty}
\newcommand{\B}{\mathcal{B}}

\newcommand{\E}{\mathrm{E}}
\newcommand{\var}{\mathrm{Var}}
\newcommand{\cov}{\mathrm{Cov}}
\newcommand{\ST}{mbox{ s.t. }}

\newcommand{\Example}{\noindent {\bf Example. \quad} }
\newcommand{\Proof}{\noindent {\bf Proof: \quad} }
\newcommand{\Remark}{\noindent {\bf Remark. \quad} }
\newcommand{\Remarks}{\noindent {\bf Remarks. \quad} }
\newcommand{\Case}{\noindent {\underline{Case} \quad} }

\newcommand{\st}{ \; \big | \:}

\newcommand{\deuc}{d_{\mathrm euc}}
\newcommand{\dtaxi}{d_{\mathrm taxi}}
\newcommand{\ddisc}{d_{\mathrm disc}}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{corollary}[theorem]{Corollary}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{example}[theorem]{Example}

\setlength{\parindent}{1cm}

\title{Opening a Cold Case \\ {\large Investigating how Temperature Affects The Rate of Robberies}}
\date{December 2, 2014}
\author{Aaron Maurer}

\begin{document}
\maketitle
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Introduction and Objective} 

With the onset of winter in Chicago, the temperature drops, and residents must concern themselves with a range of new dangers. Roads can be icy and dangerous. Heavy snow can collapse power lines and buildings. And frostbite becomes a concern on exposed skin. However, it may be the case that cold weather mitigates other dangers. When its frigid out, do criminals stay inside as well? \par

To partially investigate this question I have endeavored to quantify how the rate at which robberies occur in the city of Chicago varies with temperature. Robbery, defined as taking property from a person, without their consent, by force or threat of force\footnote{As opposed to theft, which is the taking property without consent but not necessarily by violent means, and burglary, which is breaking into a structure so as to commit a crime (whether or not a crime such as theft is committed)}, includes what is probably the most common outdoor crime, mugging. It would seem natural then that the rate at which robberies occurred would be sensitive to the weather. The this rate is distinct from one's risk of being robbed should they go outside, since it may be the case crime drops when fewer people are outside to be robbed. However, a better understanding of the former should also provide intuition for the latter question.
\par

\section{Data} 
The Chicago city government publishes a data set of which includes every crime reported to the police in the city, going back to 2001\footnote{City of Chicago. (2014). \textit{ Crimes - 2001 to present}. Retrieved from https://data.cityofchicago.org/Public-Safety/Crimes-2001-to-present/ijzp-q8t2}. I made use of the subset of this data which had a date recorded for the crime during 2011, 2012, or 2013, and which had a primary description of "Robbery", per the Illinois Uniform Crime Reporting Code. These crimes include both successful and attempted armed robbery, unarmed robbery, and vehicular hijacking. For each crime, the data set has additional information on where it occurred in the city, more detailed information about the crime, whether the crime was domestic, and if it resulted in an arrest. I, however, simply aggregated the total number of reported robberies that occurred anywhere in the city during each hour of each day during the time period. \par
I combined this hourly data with top of the hour weather data from O'Hare International Airport\footnote{Midwest Regional Climate Center. (2014). \textit{Unedited Hourly Data - Top of the Hour Observations - O'Hare International Airport}. Retrieved from mrcc.isws.illinois.edu/CLIMATE/ucld/ucld\_hrlyTop\_getdata1.jsp?WBAN=94846}. This data is a series of meteorological data, including temperature, accumulated precipitation, humidity, and wind speed, almost always measured once during a particular hour at 51 minutes after that hour. When there were multiple entries for an hour, I chose the first at 51 minutes which had the temperature recorded, or the first chronologically which had the temperature recorded if that was missing, discarding the rest. This was taken as the temperature for the city for a particular day and hour, and was matched with the hourly robbery counts. The small number ($\approx 10$) of hours for which there was no recorded temperature from O'Hare were excluded. The end result was $26,263$ hourly observations of temperature and reported robbery count, covering almost all of 2011-2013. \par
Examining this data, it is obvious that the most important feature in determining the number of robberies is the time of day, to a lesser extent, time of week. Figure 1 speaks to this effect, displaying an average by hour of the day for different temperature ranges and workday versus holiday/weekend. The mean number of robberies peaks between 6pm and 3am, possibly twice in that span, with its minimum around 6am, with the peak mean 4 to 5 times as high as the trough. This corresponds roughly to typical people's schedules; there are the most robberies during the period where people have gotten off of work for the evening, and the least when the fewest people are awake early in the morning. During the weekend, the trough and peak tend to move later, as people are up later or sleep in. \par
\begin{figure}[h]
    {\bf Figure 1} \\
    \includegraphics[width=9cm]{final_project/tempbuc_w}
    \includegraphics[width=9cm]{final_project/tempbuc_nw}
    \textit{Note: With fewer observations, the Weekend/Holiday series can be expected to be noisier}
\end{figure}
The effect of temperature seems to be less than this, and also varies with the time of day. During the middle of the day (8am to 3pm or so), it appears that the effect of temperature is at most minimal. One of the most interesting features is that in the evening, there actually appear to be fewer robberies between 6pm and 7pm when it is warm, with a much higher rate before and after. This is likely due to the changes in people's schedules that occurs when days are longer and the weather is warm. However, the strongest effect seems to be that there are far fewer robberies in the late evening and early morning when its cold. \par
\begin{figure}[h]
    {\bf Figure 2} \\
    \includegraphics[width=9cm]{final_project/ct_dist_w}
    \includegraphics[width=9cm]{final_project/ct_dist_nw}
\end{figure}
Looking at the distribution for a sample of hours in Figure 2, we once again see the effect of time of day and workday versus weekend/holiday. However, we also see a data set which seems to have, as one would hope for with count data, a Poisson distribution.

\section{Parametric Model} 
This observation points to the obvious parametric model to fit to the data, a Poisson regression model\footnote{A generalized linear model with a Poisson distribution and log link fit by maximum likelihood}. This is a natural choice, and generally considered the first parametric model to try for count data, if not the default. Its assumptions are several fold. First, it assumes that data is Poisson distributed around a particular mean, which arises when counting the sum of infrequent and independent occurrences in which a large number of these events could, in theory, occur. This assumption seems fairly safe; robberies are infrequent, and though one criminal could be responsible for multiple robberies, this effect overall can be expected to be trivial in such a large city. The less safe assumption is that the mean of this distribution can be predicted by the product of exponential functions of the set of predictors. It isn't obvious that this is true, but it is mathematically convenient, constricting the mean to positive numbers. \par
Choosing this as my model, I tried a number of specifications on an $80\%$ training subset of the data. These included various interactions of hour, as a factor and bucketed, temperature as a continuous variable, and workday versus weekend/holiday as a factor. Choosing the specification that had the best trade off of number of parameters versus likelihood, as dictated by the Akaike Information Criteria, I settled on an specification that included as predictors:
\begin{itemize}
    \item Hour of the day as a factor 
    \item Three hour buckets as a factor interacted with workday as a factor
    \item Three hour buckets as a factor interacted with the log of the sum temperature plus $50$.
\end{itemize}

Implicit in this set up is that the effect of temperature within a particular hour is assumed to be monotone. \par
\begin{figure}[h]
    {\bf Figure 3} \\
    \includegraphics[width=9cm]{final_project/poi_w_contour_fill}
    \includegraphics[width=9cm]{final_project/poi_nw_contour_fill}
\end{figure}


The estimates of the coefficients themselves are not particularly elucidating; the overall effect is best displayed graphically, such as through the heat maps in Figure 3. Here, we see the model capturing several of the features we noticed earlier. The predicted robbery rate is quite low in the late evening and early morning when it is cold, and rises quickly with the temperature, especially on the weekend. A bit later (6am or so), the crime rate is low, and throughout the middle of the day it only rises slightly with temperature. The early evening is the only area that seems outright strange; high values are predicted at low temperatures, and drops off somewhat as the temperature increases. This questionable, but is likely an artifact of the assumed monotone relationship between temperature and robbery rate paired with the small dip between higher and lower temperatures in this range. \par
This is displayed again for different three hours individually in Figure 4 along with confidence intervals. Here, we see again the patterns listed above, but also that the model predicts these big swings in robbery rate due to temperature with a great deal of certainty. Particularly, at 2am, the confidence intervals for two predictions with as little as 20 degrees separation don't overlap, asserting that they are different with much higher confidence than $95\%$. \par

\begin{figure}[h]
    {\bf Figure 4} \\
    \includegraphics[width=9cm]{final_project/poi_w_ci}
    \includegraphics[width=9cm]{final_project/poi_nw_ci}
\end{figure}

The main danger with a Poisson regression model, such as this, is that if the predicted mean function may not be able to capture fully how the mean varies. This would most likely be due to insufficient predictors being included. The result may be larger variance around the predicted mean than allowed for with the Poisson Distribution, invalidating the model. In this case, should the rest of the assumptions hold, a negative binomial regression can be used, which can be derived as a certain sum of Poisson distributions with varying means, as could be the case should the mean not be perfectly predicted by the predictors. This makes the Poisson model a particular example of a negative binomial, and a formal test can be used to decide if the additional parameter of a negative binomial is needed. Such a test might well have indicated that I should have used a negative binomial regression here, but given time constraints and a lack of familiarity, I simply went with the Poisson model. \par
Additionally, as with nonparametric models, a better tool for evaluating the fit of a particular specification of the model may have been cross validation rather than Akaike Information Criteria, since it gives a more direct estimate of over fitting. However, this model appears to under fit if anything, so cross validation may not have made such a large difference

\section{Nonparametric Model} 
To model this data with a nonparametric model, I ran separate local linear regressions on workdays and weekends/holidays, with each predicting the log of the sum number of robberies plus one with hour and temperature simultaneously. As with the Poisson model, I fit on an $80\%$ training subset. In fitting it, I used a Gaussian kernel, individual bandwidths for each point such that a constant portion of the total data was closer to the point than the bandwidth, and a relative scaling factor for the variables to determine which points were included in the neighborhood (essentially making a second component of the bandwidth for the second variable). These two values were chosen from a grid of values based on which resulting model had the lowest cross validation score. \par
The reasoning and justification for these choices are as such:
\begin{itemize}
    \item The kernel doesn't make a great deal of difference, so the choice was arbitrary. 
    \item Since I am particularly interested in how temperatures on the extreme edge of my data effect the robbery rate, I need a model with low boundary bias, making a local linear fit superior to a simpler kernel regression.
    \item Predicting log robberies nicely constrains the prediction to positive counts, which is what it should be in the real world.
    \item As the initial plots have shown, there seem to be fairly distinct trends between workdays and not workdays, so two separate models seemed more appropriate than one.
    \item Also as observed earlier, the relationship between temperature and robberies doesn't seem constant by time of day, so it would likely be insufficient to model it separately, as would be the result from a general additive model that included separate local linear models for hour and temperature
    \item The observations are not equally spaced out over their range, so one bandwidth for all the points wouldn't smooth enough on the extremes or too much in the middle. Instead, by dictating the bandwidth such it defined a neighborhood with a set number of neighbors, the amount of smoothing was comparable across the data points.
    \item Including a scaling factor for the second variable is essential, since the units of the two variables aren't comparable.
\end{itemize} \par
With this model, I am only really relying on two assumptions. First, the number or robberies as a particular time and temperature is related to the number of robberies at close time and temperatures, which is obvious. Second, I am assuming the true function is sufficiently smooth that some kind of linear fit in a  neighborhood can be used to give a reasonable prediction. If, for instance, the function had peaks and troughs more often than I had data, this method would fall apart. However, this seems unlikely from observing the data. \par
The parameters
\begin{figure}[h]
    {\bf Figure 5} \\
    \includegraphics[width=9cm]{final_project/ll_w_contour_fill}
    \includegraphics[width=9cm]{final_project/ll_nw_contour_fill}
\end{figure}
\begin{figure}[h]
    {\bf Figure 6} \\
    \includegraphics[width=9cm]{final_project/ll_w_ci}
    \includegraphics[width=9cm]{final_project/ll_nw_ci}
\end{figure}


\end{document}
