
\documentclass[11pt]{article}
\usepackage[paper=letterpaper, margin=.5in]{geometry}
\pdfpagewidth 8.5in
\pdfpageheight 11in
\setlength\parindent{0in}

%%% Packages
% First four - AMS (american mathematical society). General math goodness. I use the align* enviorment in particular
% multirow, multicol allow for certain kinds of tables
% enumerate lets you determine the style of the counter for the enumerate enviorment
% graphicx lets you include pictures
% listings lets you stick in blocks of code
% placeins defines "\FloatBarrier", which stops tables from moving around
\usepackage{amsmath, amscd, amssymb, amsthm, multirow, multicol, enumerate, graphicx, listings, placeins} 
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\C}{\mathbb{C}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\V}{\mathbb{V}}
\newcommand{\U}{\mathcal{U}}
\newcommand{\del}{\partial}
\newcommand{\real}{\textrm{Re }}
\newcommand{\imag}{\textrm{Im }}
\newcommand{\pd}[2]{\frac{\partial #1}{\partial #2}}
\newcommand{\deriv}[2]{\frac{d #1}{d #2}}
\newcommand{\sumk}{\sum_{k=1}^\infty}
\newcommand{\sumj}{\sum_{j=1}^\infty}
\newcommand{\sumn}{\sum_{n=0}^\infty}
\newcommand{\summ}[2]{\sum_{k=#1}^{#2}}
\newcommand{\sig}[1]{\sum_{#1 =1}^\infty}
\newcommand{\un}[1]{\bigcup_{#1 =1}^\infty}
\newcommand{\inter}[1]{\bigcap_{#1 =1}^\infty}
\newcommand{\ip}[2]{\langle #1, #2 \rangle}
\newcommand{\ipxu}{\langle x,u_j \rangle}
\newcommand{\uj}{\{u_j\}_{j=1}^\infty}
\newcommand{\B}{\mathcal{B}}

\newcommand{\E}{\mathrm{E}}
\newcommand{\var}{\mathrm{Var}}
\newcommand{\cov}{\mathrm{Cov}}
\newcommand{\ST}{mbox{ s.t. }}

\newcommand{\Example}{\noindent {\bf Example. \quad} }
\newcommand{\Proof}{\noindent {\bf Proof: \quad} }
\newcommand{\Remark}{\noindent {\bf Remark. \quad} }
\newcommand{\Remarks}{\noindent {\bf Remarks. \quad} }
\newcommand{\Case}{\noindent {\underline{Case} \quad} }

\newcommand{\st}{ \; \big | \:}

\newcommand{\deuc}{d_{\mathrm euc}}
\newcommand{\dtaxi}{d_{\mathrm taxi}}
\newcommand{\ddisc}{d_{\mathrm disc}}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{corollary}[theorem]{Corollary}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{example}[theorem]{Example}

\setlength{\parindent}{1cm}

\title{Opening a Cold Case \\ {\large Investigating how Temperature Affects The Rate of Robberies}}
\date{December 2, 2014}
\author{Aaron Maurer}

\begin{document}
\maketitle
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Introduction and Objective} 

With the onset of winter in Chicago, the temperature drops, and residents must concern themselves with a range of new dangers. Roads can be icy and dangerous. Heavy snow can collapse power lines and buildings. And frostbite becomes a concern on exposed skin. However, it may be the case that cold weather mitigates other dangers. When its frigid out, do criminals stay inside as well? \par

To partially investigate this question I have endeavored to quantify how the rate at which robberies occur in the city of Chicago varies with temperature. Robbery, defined as taking property from a person, without their consent, by force or threat of force\footnote{As opposed to theft, which is the taking property without consent but not necessarily by violent means, and burglary, which is breaking into a structure so as to commit a crime (whether or not a crime such as theft is committed)}, includes what is probably the most common outdoor crime, mugging. It would seem natural then that the rate at which robberies occurred would be sensitive to the weather. The this rate is distinct from one's risk of being robbed should they go outside, since it may be the case crime drops when fewer people are outside to be robbed. However, a better understanding of the former should also provide intuition for the latter question.
\par

\section{Data} 
The Chicago city government publishes a data set of which includes every crime reported to the police in the city, going back to 2001\footnote{City of Chicago. (2014). \textit{ Crimes - 2001 to present}. Retrieved from https://data.cityofchicago.org/Public-Safety/Crimes-2001-to-present/ijzp-q8t2}. I made use of the subset of this data which had a date recorded for the crime during 2011, 2012, or 2013, and which had a primary description of "Robbery", per the Illinois Uniform Crime Reporting Code. These crimes include both successful and attempted armed robbery, unarmed robbery, and vehicular hijacking. For each crime, the data set has additional information on where it occurred in the city, more detailed information about the crime, whether the crime was domestic, and if it resulted in an arrest. I, however, simply aggregated the total number of reported robberies that occurred anywhere in the city during each hour of each day during the time period. \par
I combined this hourly data with top of the hour weather data from O'Hare International Airport\footnote{Midwest Regional Climate Center. (2014). \textit{Unedited Hourly Data - Top of the Hour Observations - O'Hare International Airport}. Retrieved from mrcc.isws.illinois.edu/CLIMATE/ucld/ucld\_hrlyTop\_getdata1.jsp?WBAN=94846}. This data is a series of meteorological data, including temperature, accumulated precipitation, humidity, and wind speed, almost always measured once during a particular hour at 51 minutes after that hour. When there were multiple entries for an hour, I chose the first at 51 minutes which had the temperature recorded, or the first chronologically which had the temperature recorded if that was missing, discarding the rest. This was taken as the temperature for the city for a particular day and hour, and was matched with the hourly robbery counts. The small number ($\approx 10$) of hours for which there was no recorded temperature from O'Hare were excluded. The end result was $26,263$ hourly observations of temperature and reported robbery count, covering almost all of 2011-2013. \par
Examining this data, it is obvious that the most important feature in determining the number of robberies is the time of day, to a lesser extent, time of week. Figure 1 speaks to this effect, displaying an average by hour of the day for different temperature ranges and workday versus holiday/weekend. The mean number of robberies peaks between 6pm and 3am, possibly twice in that span, with its minimum around 6am, with the peak mean 4 to 5 times as high as the trough. This corresponds roughly to typical people's schedules; there are the most robberies during the period where people have gotten off of work for the evening, and the least when the fewest people are awake early in the morning. During the weekend, the trough and peak tend to move later, as people are up later or sleep in. \par
\begin{figure}[h]
    {\bf Figure 1} \\
    \includegraphics[width=9cm]{final_project/tempbuc_w}
    \includegraphics[width=9cm]{final_project/tempbuc_nw}
    \textit{Note: With fewer observations, the Weekend/Holiday series can be expected to be noisier}
\end{figure}
The effect of temperature seems to be less than this, and also varies with the time of day. During the middle of the day (8am to 3pm or so), it appears that the effect of temperature is at most minimal. One of the most interesting features is that in the evening, there actually appear to be fewer robberies between 6pm and 7pm when it is warm, with a much higher rate before and after. This is likely due to the changes in people's schedules that occurs when days are longer and the weather is warm. However, the strongest effect seems to be that there are far fewer robberies in the late evening and early morning when its cold. \par
\begin{figure}[h]
    {\bf Figure 2} \\
    \includegraphics[width=9cm]{final_project/ct_dist_w}
    \includegraphics[width=9cm]{final_project/ct_dist_nw}
\end{figure}
Looking at the distribution for a sample of hours in Figure 2, we once again see the effect of time of day and workday versus weekend/holiday. However, we also see a data set which seems to have, as one would hope for with count data, a Poisson distribution.

\section{Parametric Model} 
This observation points to the obvious parametric model to fit to the data, a Poisson regression model\footnote{A generalized linear model with a Poisson distribution and log link fit by maximum likelihood}. This is a natural choice, and generally considered the first parametric model to try for count data, if not the default. Its assumptions are several fold. First, it assumes that data is Poisson distributed around a particular mean, which arises when counting the sum of infrequent and independent occurrences in which a large number of these events could, in theory, occur. This assumption seems fairly safe; robberies are infrequent, and though one criminal could be responsible for multiple robberies, this effect overall can be expected to be trivial in such a large city. The less safe assumption is that the mean of this distribution can be predicted by the product of exponential functions of the set of predictors. It isn't obvious that this is true, but it is mathematically convenient, constricting the mean to positive numbers. \par
Choosing this as my model, I tried a number of specifications on an $80\%$ training subset of the data. These included various interactions of hour, as a factor and bucketed, temperature as a continuous variable, and workday versus weekend/holiday as a factor. Choosing the specification that had the best trade off of number of parameters versus likelihood, as dictated by the Akaike Information Criteria, I settled on an specification that included as predictors:
\begin{itemize}
    \item Hour of the day as a factor 
    \item Three hour buckets as a factor interacted with workday as a factor
    \item Three hour buckets as a factor interacted with the log of the sum temperature plus $50$.
\end{itemize}

Implicit in this set up is that the effect of temperature within a particular hour is assumed to be monotone. \par
\begin{figure}[h]
    {\bf Figure 3} \\
    \includegraphics[width=9cm]{final_project/poi_w_contour_fill}
    \includegraphics[width=9cm]{final_project/poi_nw_contour_fill}
\end{figure}


The estimates of the coefficients themselves are not particularly elucidating; the overall effect is best displayed graphically, such as through the heat maps in Figure 3. Here, we see the model capturing several of the features we noticed earlier. The predicted robbery rate is quite low in the late evening and early morning when it is cold, and rises quickly with the temperature, especially on the weekend. A bit later (6am or so), the crime rate is low, and throughout the middle of the day it only rises slightly with temperature. The early evening is the only area that seems outright strange; high values are predicted at low temperatures, and drops off somewhat as the temperature increases. This questionable, but is likely an artifact of the assumed monotone relationship between temperature and robbery rate paired with the small dip between higher and lower temperatures in this range. \par
This is displayed again for different three hours individually in Figure 4 along with confidence intervals. Here, we see again the patterns listed above, but also that the model predicts these big swings in robbery rate due to temperature with a great deal of certainty. Particularly, at 2am, the confidence intervals for two predictions with as little as 20 degrees separation don't overlap, asserting that they are different with much higher confidence than $95\%$. \par

\begin{figure}[h]
    {\bf Figure 4} \\
    \includegraphics[width=9cm]{final_project/poi_w_ci}
    \includegraphics[width=9cm]{final_project/poi_nw_ci}
\end{figure}

The main danger with a Poisson regression model, such as this, is that if the predicted mean function may not be able to capture fully how the mean varies. This would most likely be due to insufficient predictors being included. The result may be larger variance around the predicted mean than allowed for with the Poisson Distribution, invalidating the model. In this case, should the rest of the assumptions hold, a negative binomial regression can be used, which can be derived as a certain sum of Poisson distributions with varying means, as could be the case should the mean not be perfectly predicted by the predictors. This makes the Poisson model a particular example of a negative binomial, and a formal test can be used to decide if the additional parameter of a negative binomial is needed. Such a test might well have indicated that I should have used a negative binomial regression here, but given time constraints and a lack of familiarity, I simply went with the Poisson model. \par
Additionally, as with nonparametric models, a better tool for evaluating the fit of a particular specification of the model may have been cross validation rather than Akaike Information Criteria, since it gives a more direct estimate of over and under fitting. 

\section{Nonparametric Model} 
To model this data with a nonparametric model, I ran separate local linear regressions on workdays and weekends/holidays, with each predicting the log of the sum number of robberies plus one with hour and temperature simultaneously. As with the Poisson model, I fit on an $80\%$ training subset. In fitting it, I used a Gaussian kernel, individual bandwidths for each point such that a constant portion of the total data was closer to the point than the bandwidth, and a relative scaling factor for the second variable (this effectively stretches or shrinks the kernel in one direction). These two values were chosen from a grid of values based on which resulting model had the lowest cross validation score. As well, the hour span was expanded to include the previous and next day's data, so there should be no boundary bias towards the beginning and end of days.\par
The reasoning and justification for these choices are as such:
\begin{itemize}
    \item The kernel doesn't make a great deal of difference, so the choice was arbitrary. 
    \item Since I am particularly interested in how temperatures on the extreme edge of my data effect the robbery rate. This necessitates a need a model with low boundary bias along the temperature range, making a local linear fit superior to a simpler kernel regression. Higher polynomial fits on the other hand make it increasingly difficult to fit the model well.
    \item Predicting log robberies nicely constrains the prediction to positive counts, which is what it should be in the real world.
    \item As the initial plots have shown, there seem to be fairly distinct trends between workdays and not workdays, so two separate models seemed more appropriate than one. 
    \item Also as observed earlier, the relationship between temperature and robberies doesn't appear constant by time of day, so it would likely be insufficient to model it separately, as would be the result from a general additive model that included separate local linear models for hour and temperature. In this case, there is a sufficient amount of data to still have a reasonable degree of accuracy, so the curse of dimensionality is not prohibitive.  
    \item The observations are not equally spaced out over their range, so one bandwidth for all the points wouldn't smooth enough on the extremes or too much in the middle. Instead, by dictating the bandwidth such that it defined a neighborhood with a fixed number of neighbors, the amount of smoothing was comparable across the data points.
    \item Including a scaling factor for the second variable is essential, since the units of the two variables aren't comparable.
\end{itemize} \par
With this model, I am only really relying on two assumptions. First, the number or robberies as a particular time and temperature is related to the number of robberies at close time and temperatures, which is obvious. Second, I am assuming sufficient smoothness to achieve convergence of the estimates. \par
\begin{figure}[h]
    {\bf Figure 5} \\
    \includegraphics[width=9cm]{final_project/ll_w_contour_fill}
    \includegraphics[width=9cm]{final_project/ll_nw_contour_fill}
\end{figure}
\FloatBarrier
The predictions of the models can be seen in the contour plots of Figure 5. It is important to note that with less data, bandwidths for the weekend/holiday model were chosen to include a larger portion of the data, and also that the scale was such that this model averaged more strongly over temperature than hour as compared to the workday model. This model seems to very clearly portray the patterns we have seen before. Peak crime on workdays is highest in the evening, with the main peak later and a second, smaller and earlier, peak developing when the temperature is higher. Also, the afternoon and evening crime rate does fall off as the temperature increases beyond a point. On non-workdays, the peak is in the earliest hours of the morning, and keeps increasing with the temperature. However, the prediction for the highest temperatures should be taken with a grain of salt; their is little if any data where temperatures actually reach that high at that hour of the day.
\FloatBarrier

\begin{figure}[h]
    {\bf Figure 6} \\
    \includegraphics[width=9cm]{final_project/ll_w_ci}
    \includegraphics[width=9cm]{final_project/ll_nw_ci}
\end{figure}
Evaluating the confidence of the fits, as seen in Figure 6, we see a much more nuanced picture for workdays than we saw from the Poisson model. It should be noted that the confidence intervals are based on local estimates of variance, necessitated by the variable bandwidth. This model is quite certain that the peak crime rate at $6$pm on workdays occurs when the temperature is between 30 and 50 degrees, and falls off afterwards, as opposed to the monotonic relationship predicted by the Poisson model. It also has a large amount of confidence there is a true increase in crime in the early morning, though as I noted, at high temperatures there is much more uncertainty. With much more smoothing, particularly over temperature, in the weekend/holiday model, its results look similar to the Poisson models. \par
It seems safe to say this model is the strongest non-parametric regression for this subject. Alternate linear smoothers and generalized additive models were discussed earlier. Monotonicity with hour or temperature doesn't seem to hold, nor does convexity/concavity, so models making those assumptions aren't appropriate. This series doesn't have the quickly varying features that would necessitate a procedure like wavelet regression. However, what could be quite a good alternate approach is to not have aggregated robbery counts, and fit a density estimate to the data. This could be scaled by how often different temperature and hour combinations occurred to give relative rates of robbery. This approach has the advantage of preserving more information about the time a crime occurs, but is computationally more intensive (with more data points), and doesn't easily admit a comparable parametric model.

\section{Discussion} 
Comparing the two models just based on performance, the nonparametric model wins, though they both do fairly well. I calculated the root mean squared log error for each model over the $20\%$ test subset that wasn't used to train the models. The local linear model had a RMSLE of $.510$, while the Poisson model had a RMSLE of $.529$. By comparison, an unbiased estimate where the mean at each temperature/hour combination in the training data was taken had a RMSLE of $.563$, so both models are a meaningful improvement. \par
Subjectively, they both picked up mostly the same trends. The only notable distinction was in how they treated the late afternoon and early evening period, with the Poisson model apparently failing to capture the non-monotone trend. However, by including more and varied predictors (from interactions, splines, transformations, etc.), one can get and arbitrary degree of flexibility. Choosing a sufficient set of predictors is a slow process to do manually though, making it easier to just start with a non-parametric method which has arbitrary flexibility built in. One could meet halfway between the methods with a nonparametric model fit with local likelihood, since the assumption that the error is Poisson or negative binomial distributed seems appropriate. \par
In terms of interpretation, both are pretty convincingly show that the rate of robberies varies with temperature, generally increasing with it. Causation is quite unclear though; temperature is highly correlated with a number of other seasonal factors. One could reasonably expect the rate of robberies to vary with school holidays, daylight hours, or just the time of the year irrespective of season. By including all these factors in a model, it would likely be highly predictive, but the high collinearity can be expected to make it hard to attribute changes to just one factor, modeled parametrically or not. Appropriately modeling these effects would be the most important extension of the current model. \par
There are a number of other areas where this model could be expanded though. There is a great wealth of geographic data in the Chicago crime database, and there is likely a great deal of heterogeneity in the baseline rate of robberies by geography, as well as the differences in the effect of weather on that rate. Different types of crime could also be investigated. Different attributes of the weather may also play a roll. I initially investigated the effect of precipitation on the robbery rate. The presence of precipitation, as showed in Figure 7, does seem to coincide with a small reduction in robberies, at least in during the late evening and early morning. This effect appears to vary a lot with the amount of precipitation, and there were relatively little data from when there was enough precipitation to have a meaningful effect. With the Poisson model, every version I tried which included precipitation in some form had an inferior AIC, so ultimately I decided not to model it, at least for now. Finally, there is slight asymmetry between the early morning and late evening predictions due to how the weekends are defined. Friday evening is likely more akin to a Saturday night, with more robberies, pushing up the late evening average of workdays as compared to the early mornings, while Sunday evening likely has the opposite effect on the Weekends/Holidays. A modified delineation between the two periods may have done away with this, improving the fit. There may be further clustering that could be preformed on the days as well. All these areas present opportunity for further refinement.

\begin{figure}[h]
    {\bf Figure 7} \\
    \includegraphics[width=9cm]{final_project/precip}
\end{figure}
\end{document}
