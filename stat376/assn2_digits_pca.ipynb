{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Initialization\n",
      "from math import * \n",
      "import base64\n",
      "import re\n",
      "import json \n",
      "import numpy as np\n",
      "import matplotlib as mp\n",
      "import random as rand\n",
      "import matplotlib.pyplot as plt\n",
      "from collections import namedtuple \n",
      "\n",
      "# Am I working on AWS?\n",
      "AWS = False\n",
      "\n",
      "# Check Spark is working\n",
      "print sc "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<pyspark.context.SparkContext object at 0x7fdc8caf3950>\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "2. PCA on scanned digits"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "if AWS:\n",
      "    rawData = \"s3n://stat-37601/digits.base64.json\"\n",
      "else:\n",
      "    rawData = \"data/digits.base64.json\"\n",
      "\n",
      "def parse(x):\n",
      "    digit = json.loads(x)\n",
      "    array = np.fromstring(base64.b64decode(digit[\"data\"]),dtype=np.ubyte)\n",
      "    return [(np.array([digit[\"label\"]]), array)]\n",
      "\n",
      "def viewImage(vec,pltimg):\n",
      "    vec = vec.astype(float)/256\n",
      "    plt.figure(pltimg)\n",
      "    fig = plt.imshow(vec.reshape(28,28))\n",
      "    fig.set_cmap('gray_r')\n",
      "    fig.axes.get_xaxis().set_visible(False)\n",
      "    fig.axes.get_yaxis().set_visible(False)\n",
      "\n",
      "# I found that this is much quicker than using a reduce statement to join the vectors into a matrix\n",
      "imageData =sc.textFile(rawData).map(parse).reduce(lambda x,y: x+y)\n",
      "imgMatrix =      np.vstack([img[1] for img in imageData])\n",
      "labels    = np.concatenate([img[0] for img in imageData])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "(a) Standardize data and extract PCA"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "Often one would want to use robust estimates of mean and variance to standardize variables for a PCA analysis. However, this data is bounded above and below, with the majority of values on one of those bounds, so that shouldn't be necessary."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Rows are images, columns are pixels\n",
      "images,pixels = imgMatrix.shape\n",
      "\n",
      "pixMeans = np.mean(imgMatrix,axis=0)\n",
      "pixSDs   = np.max(np.vstack((np.std(imgMatrix,axis=0),np.ones(pixels)/100)),axis=0) # When SD=0, set it to .01 so we don't divide by 0\n",
      "\n",
      "standMatrix = np.minimum((imgMatrix - pixMeans)/pixSDs,3*np.ones((images,pixels)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}