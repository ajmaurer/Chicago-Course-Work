{"nbformat_minor": 0, "cells": [{"execution_count": 2, "cell_type": "code", "source": "# Imports\nimport json, re, numpy as np, numpy.linalg as nplin, matplotlib.pyplot as plt, matplotlib.mlab as mlab, scipy.stats as spstat\nfrom __future__ import division\nfrom pyspark.mllib.feature import HashingTF, IDF, Normalizer\nfrom pyspark.mllib.regression import LabeledPoint\nfrom pyspark.mllib.tree import DecisionTree, RandomForest, GradientBoostedTrees\nfrom operator import itemgetter\nfrom time import time\n%matplotlib inline", "outputs": [], "metadata": {"collapsed": true, "trusted": true}}, {"execution_count": 3, "cell_type": "code", "source": "# Load data, split into test and training set\nall_reviews = sc.textFile(\"s3n://stat-37601/ratings.json\", minPartitions=1000).map(json.loads)\nreviews, reviews_test = all_reviews.randomSplit([.7, .3])\nreviews.cache()", "outputs": [{"execution_count": 3, "output_type": "execute_result", "data": {"text/plain": "PythonRDD[4] at RDD at PythonRDD.scala:42"}, "metadata": {}}], "metadata": {"collapsed": false, "trusted": true}}, {"source": "Get the variable we are regressing on: a continious score out of 1", "cell_type": "markdown", "metadata": {}}, {"execution_count": 4, "cell_type": "code", "source": "# Get the variable we are regressing on, the review as a score out of 1\ndef getLabel(review):\n    \"\"\"Get the overall rating from a review\"\"\"\n    label, total = review[\"review_overall\"].split(\"/\")\n    return float(label) / float(total)\n\nlabels      = reviews.map(getLabel)\nlabels_test = reviews_test.map(getLabel)", "outputs": [], "metadata": {"collapsed": true, "trusted": true}}, {"source": "#### (a) Generating features (hashed TF-IDF)\nWe generate a list of words (the features) for each review, transform them into hashes, calculate term frequency-inverse document frequency accross corpus, and normalize", "cell_type": "markdown", "metadata": {}}, {"execution_count": 5, "cell_type": "code", "source": "# Parser, mostly from earlier problem using SGD on tweets, except without code for emoticions\n\n# words to ignore\nstop = set(['the', 'and', 'you', 'your', 'for', 'por', 'que', 'las', 'los', 'les',\\\n       'una', 'del', 'este', 'usted', 'para', 'con', 'this', 'that', 'was', 'have', 'like',\\\n       'would', 'could', 'should', 'will', 'can', 'shall', 'just', 'all', 'it', 'its', 'per'])\neng_stop = set(['i', 'me', 'my', 'myself', 'we', 'our', \\\n             'ours', 'ourselves', 'you', 'your', 'yours', \\\n             'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers', 'herself', \\\n             'it', 'its', 'itself', 'they', 'them', 'their', 'theirs', \\\n             'themselves', 'what', 'which', 'who', 'whom', 'this', \\\n             'that', 'these', 'those', 'am', 'is', 'are', 'was', 'were', \\\n             'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do',\\\n             'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', \\\n             'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at',\\\n             'by', 'for', 'with', 'about', 'against', 'between', 'into', \\\n             'through', 'during', 'before', 'after', \\\n            'above', 'below', 'to', 'from', 'up', 'down', 'in',\\\n            'out', 'on', 'off', 'over', 'under', 'again', 'further', \\\n            'then', 'once', 'here', 'there', 'when', 'where', 'why', \\\n            'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most',\\\n            'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', \\\n            'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', \\\n            'just', 'dont', 'should', 'now','on'])\nspa_stop = set()\nall_stop = stop|eng_stop|spa_stop\n\n# word processor function\ndef splitter(s,ignore=all_stop):\n    s = re.sub(\"([a-zA-Z])'([a-zA-Z])\",\"\\g<1>\\g<2>\",s) # standardize to no apostrophe\n    s = re.sub('[^a-zA-Z!\\?]',' ',s)           # get rid of most punctuation \n    s = re.sub('\\?![\\?!]*|!\\?[\\?!]*',' !? ',s) # standardize ?!?!?!\n    s = re.sub('!+','!',s)                    # standardize to single !\n    s = re.sub('\\?+','?',s)                   # standarize to single ?\n    s = re.sub('([a-zA-z]{2,})([?!]+)(\\s|$)','\\g<1> \\g<2> ',s) # single out punctuation\n    s = re.sub('(?!http://)www\\.\\S+|http://\\S+','',s) # get rid of urls\n    return list([w.lower() for w in s.split() if w not in ignore])", "outputs": [], "metadata": {"collapsed": false, "trusted": true}}, {"execution_count": 6, "cell_type": "code", "source": "# Do the hashing transform\nrevHTF = HashingTF(numFeatures=200)\nreviewFrequency      = revHTF.transform(     reviews.map(lambda review: splitter(review[\"review_text\"]))).cache()\nreview_testFrequency = revHTF.transform(reviews_test.map(lambda review: splitter(review[\"review_text\"]))).cache()\n\n# Do the inverse document frequency transform\nrevIDF = IDF().fit(reviewFrequency)\nnor = Normalizer(p=2)\nfeatures      = nor.transform(revIDF.transform(reviewFrequency)).cache()\nfeatures_test = nor.transform(revIDF.transform(review_testFrequency)).cache()\n\n# Un-cache unneeded data sets\nreviewFrequency.unpersist()\nreview_testFrequency.unpersist()", "outputs": [{"execution_count": 6, "output_type": "execute_result", "data": {"text/plain": "PythonRDD[6] at RDD at PythonRDD.scala:42"}, "metadata": {}}], "metadata": {"collapsed": false, "trusted": true}}, {"execution_count": 7, "cell_type": "code", "source": "# Join the labels back with the features\ndata = features.zip(labels).map(lambda (feature, label): LabeledPoint(label, feature))", "outputs": [], "metadata": {"collapsed": true, "trusted": true}}, {"source": "#### (b) The regression model and evaluation\nWrite a function to compute MSE for training and test datasets", "cell_type": "markdown", "metadata": {}}, {"execution_count": 9, "cell_type": "code", "source": "def treeMSE(tree,train_feat=features,train_label=labels,test_feat=features_test,test_label=labels_test):\n    '''Evaluates training and test error for a pyspark mllib tree model'''\n    train_MSE = train_label.zip(tree.predict(train_feat)).map(lambda (l,p):(l-p)**2).sum() / train_label.count()\n    test_MSE  = test_label.zip(tree.predict(test_feat)).map(lambda (l,p):(l-p)**2).sum() / test_label.count()\n    return(train_MSE,test_MSE)", "outputs": [], "metadata": {"collapsed": false, "trusted": true}}, {"source": "####(c) train and test some trees\nTest out some parameterizations of gradient boosted trees and random forrests", "cell_type": "markdown", "metadata": {}}, {"execution_count": 20, "cell_type": "code", "source": "# Try with max depth 4 and max bins 25\ntree_ct = [10,50,100,200]\nmodel_set1 = []\nfor i in range(len(tree_ct)):\n    model_set1.append(RandomForest.trainRegressor(data=data,categoricalFeaturesInfo={},numTrees=tree_ct[i],impurity='variance',maxDepth=4,maxBins=25))\n    trerr,teerr = treeMSE(model_set1[i])\n    print 'With %d trees, got %.4f training error MSE and %.4f testing error' % (tree_ct[i],trerr,teerr)", "outputs": [{"ename": "KeyboardInterrupt", "evalue": "", "traceback": ["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m", "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)", "\u001b[1;32m<ipython-input-20-4de7a3c79ffa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mmodel_set1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtree_ct\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mmodel_set1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRandomForest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainRegressor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcategoricalFeaturesInfo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnumTrees\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtree_ct\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mimpurity\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'variance'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmaxDepth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmaxBins\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m25\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mtrerr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mteerr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtreeMSE\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_set1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mprint\u001b[0m \u001b[1;34m'With %d trees, got %.4f training error MSE and %.4f testing error'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtree_ct\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrerr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mteerr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n", "\u001b[1;32m/root/spark/python/pyspark/mllib/tree.pyc\u001b[0m in \u001b[0;36mtrainRegressor\u001b[1;34m(cls, data, categoricalFeaturesInfo, numTrees, featureSubsetStrategy, impurity, maxDepth, maxBins, seed)\u001b[0m\n\u001b[0;32m    412\u001b[0m         \"\"\"\n\u001b[0;32m    413\u001b[0m         return cls._train(data, \"regression\", 0, categoricalFeaturesInfo, numTrees,\n\u001b[1;32m--> 414\u001b[1;33m                           featureSubsetStrategy, impurity, maxDepth, maxBins, seed)\n\u001b[0m\u001b[0;32m    415\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    416\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n", "\u001b[1;32m/root/spark/python/pyspark/mllib/tree.pyc\u001b[0m in \u001b[0;36m_train\u001b[1;34m(cls, data, algo, numClasses, categoricalFeaturesInfo, numTrees, featureSubsetStrategy, impurity, maxDepth, maxBins, seed)\u001b[0m\n\u001b[0;32m    266\u001b[0m         model = callMLlibFunc(\"trainRandomForestModel\", data, algo, numClasses,\n\u001b[0;32m    267\u001b[0m                               \u001b[0mcategoricalFeaturesInfo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumTrees\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatureSubsetStrategy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimpurity\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 268\u001b[1;33m                               maxDepth, maxBins, seed)\n\u001b[0m\u001b[0;32m    269\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mRandomForestModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n", "\u001b[1;32m/root/spark/python/pyspark/mllib/common.pyc\u001b[0m in \u001b[0;36mcallMLlibFunc\u001b[1;34m(name, *args)\u001b[0m\n\u001b[0;32m    118\u001b[0m     \u001b[0msc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_active_spark_context\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m     \u001b[0mapi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPythonMLLibAPI\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 120\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mcallJavaFunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mapi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    121\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n", "\u001b[1;32m/root/spark/python/pyspark/mllib/common.pyc\u001b[0m in \u001b[0;36mcallJavaFunc\u001b[1;34m(sc, func, *args)\u001b[0m\n\u001b[0;32m    111\u001b[0m     \u001b[1;34m\"\"\" Call Java Function \"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m     \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_py2java\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 113\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_java2py\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    114\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n", "\u001b[1;32m/root/spark/python/lib/py4j-0.8.2.1-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mEND_COMMAND_PART\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    535\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 536\u001b[1;33m         \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    537\u001b[0m         return_value = get_return_value(answer, self.gateway_client,\n\u001b[0;32m    538\u001b[0m                 self.target_id, self.name)\n", "\u001b[1;32m/root/spark/python/lib/py4j-0.8.2.1-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[1;34m(self, command, retry)\u001b[0m\n\u001b[0;32m    362\u001b[0m         \u001b[0mconnection\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_connection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    363\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 364\u001b[1;33m             \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    365\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_give_back_connection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconnection\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    366\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mPy4JNetworkError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n", "\u001b[1;32m/root/spark/python/lib/py4j-0.8.2.1-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[1;34m(self, command)\u001b[0m\n\u001b[0;32m    471\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    472\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msocket\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msendall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 473\u001b[1;33m             \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msmart_decode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    474\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Answer received: {0}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    475\u001b[0m             \u001b[1;31m# Happens when a the other end is dead. There might be an empty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n", "\u001b[1;32m/usr/lib64/python2.7/socket.pyc\u001b[0m in \u001b[0;36mreadline\u001b[1;34m(self, size)\u001b[0m\n\u001b[0;32m    428\u001b[0m                     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    429\u001b[0m                         \u001b[1;32mwhile\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"\\n\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 430\u001b[1;33m                             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrecv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    431\u001b[0m                             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    432\u001b[0m                                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n", "\u001b[1;31mKeyboardInterrupt\u001b[0m: "], "output_type": "error"}], "metadata": {"collapsed": false, "trusted": true}}, {"execution_count": 22, "cell_type": "code", "source": "data.first()", "outputs": [{"execution_count": 22, "output_type": "execute_result", "data": {"text/plain": "LabeledPoint(0.65, (200,[4,11,13,22,24,25,27,33,50,52,56,58,59,63,64,65,70,80,82,85,89,99,107,108,119,131,134,136,145,147,154,165,180,182,197],[0.141163122096,0.0848617805965,0.194507454629,0.0653701750114,0.206978944929,0.174202784802,0.178482338124,0.31602357641,0.0273267120337,0.0913483562267,0.137811956963,0.112282703109,0.189166311459,0.149165035609,0.09702746755,0.157565939941,0.202648900664,0.182884669945,0.102862297485,0.140775263599,0.146906972512,0.0952654612478,0.185043022887,0.0965378478626,0.155861932571,0.142806504543,0.422373013109,0.15792877968,0.169229685058,0.0856679785379,0.077250348088,0.190830034892,0.171815133163,0.191848073218,0.145055340388]))"}, "metadata": {}}], "metadata": {"collapsed": false, "trusted": true}}, {"execution_count": null, "cell_type": "code", "source": "", "outputs": [], "metadata": {"collapsed": true, "trusted": true}}], "nbformat": 4, "metadata": {"kernelspec": {"display_name": "Python 2", "name": "python2", "language": "python"}, "language_info": {"mimetype": "text/x-python", "nbconvert_exporter": "python", "version": "2.7.9", "name": "python", "file_extension": ".py", "pygments_lexer": "ipython2", "codemirror_mode": {"version": 2, "name": "ipython"}}}}