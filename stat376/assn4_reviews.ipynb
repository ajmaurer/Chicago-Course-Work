{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import json, re, numpy as np, numpy.linalg as nplin, matplotlib.pyplot as plt, matplotlib.mlab as mlab, scipy.stats as spstat\n",
    "from __future__ import division\n",
    "from pyspark.mllib.feature import HashingTF, IDF, Normalizer\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.mllib.tree import DecisionTree, RandomForest, GradientBoostedTrees\n",
    "from operator import itemgetter\n",
    "from time import time\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[2] at RDD at PythonRDD.scala:42"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data, split into test and training set\n",
    "all_reviews = sc.textFile(\"s3n://stat-37601/ratings.json\", minPartitions=1000).map(json.loads)\n",
    "reviews, reviews_test = all_reviews.randomSplit([.7, .3])\n",
    "reviews.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the variable we are regressing on: a continious score out of 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get the variable we are regressing on, the review as a score out of 1\n",
    "def getLabel(review):\n",
    "    \"\"\"Get the overall rating from a review\"\"\"\n",
    "    label, total = review[\"review_overall\"].split(\"/\")\n",
    "    return float(label) / float(total)\n",
    "\n",
    "labels      = reviews.map(getLabel)\n",
    "labels_test = reviews_test.map(getLabel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (a) Generating features (hashed TF-IDF)\n",
    "We generate a list of words (the features) for each review, transform them into hashes, calculate term frequency-inverse document frequency accross corpus, and normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Parser, mostly from earlier problem using SGD on tweets, except without code for emoticions\n",
    "\n",
    "# words to ignore\n",
    "stop = set(['the', 'and', 'you', 'your', 'for', 'por', 'que', 'las', 'los', 'les',\\\n",
    "       'una', 'del', 'este', 'usted', 'para', 'con', 'this', 'that', 'was', 'have', 'like',\\\n",
    "       'would', 'could', 'should', 'will', 'can', 'shall', 'just', 'all', 'it', 'its', 'per'])\n",
    "eng_stop = set(['i', 'me', 'my', 'myself', 'we', 'our', \\\n",
    "             'ours', 'ourselves', 'you', 'your', 'yours', \\\n",
    "             'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers', 'herself', \\\n",
    "             'it', 'its', 'itself', 'they', 'them', 'their', 'theirs', \\\n",
    "             'themselves', 'what', 'which', 'who', 'whom', 'this', \\\n",
    "             'that', 'these', 'those', 'am', 'is', 'are', 'was', 'were', \\\n",
    "             'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do',\\\n",
    "             'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', \\\n",
    "             'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at',\\\n",
    "             'by', 'for', 'with', 'about', 'against', 'between', 'into', \\\n",
    "             'through', 'during', 'before', 'after', \\\n",
    "            'above', 'below', 'to', 'from', 'up', 'down', 'in',\\\n",
    "            'out', 'on', 'off', 'over', 'under', 'again', 'further', \\\n",
    "            'then', 'once', 'here', 'there', 'when', 'where', 'why', \\\n",
    "            'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most',\\\n",
    "            'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', \\\n",
    "            'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', \\\n",
    "            'just', 'dont', 'should', 'now','on'])\n",
    "spa_stop = set()\n",
    "all_stop = stop|eng_stop|spa_stop\n",
    "\n",
    "# word processor function\n",
    "def splitter(s,ignore=all_stop):\n",
    "    s = re.sub(\"([a-zA-Z])'([a-zA-Z])\",\"\\g<1>\\g<2>\",s) # standardize to no apostrophe\n",
    "    s = re.sub('[^a-zA-Z!\\?]',' ',s)           # get rid of most punctuation \n",
    "    s = re.sub('\\?![\\?!]*|!\\?[\\?!]*',' !? ',s) # standardize ?!?!?!\n",
    "    s = re.sub('!+','!',s)                    # standardize to single !\n",
    "    s = re.sub('\\?+','?',s)                   # standarize to single ?\n",
    "    s = re.sub('([a-zA-z]{2,})([?!]+)(\\s|$)','\\g<1> \\g<2> ',s) # single out punctuation\n",
    "    s = re.sub('(?!http://)www\\.\\S+|http://\\S+','',s) # get rid of urls\n",
    "    return list([w.lower() for w in s.split() if w not in ignore])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I only take 200 features for the hashing space. This means there are going to be a huge number of collisions, resulting in a large but unintelligent dimmensionality reduction. The computational time and space issues become prohibitive without a large reduction though. We still end up with some predictive power anyway though, so we aren't totally ruining the regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[4] at RDD at PythonRDD.scala:42"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Do the hashing transform.\n",
    "revHTF = HashingTF(numFeatures=200)\n",
    "reviewFrequency      = revHTF.transform(     reviews.map(lambda review: splitter(review[\"review_text\"]))).cache()\n",
    "review_testFrequency = revHTF.transform(reviews_test.map(lambda review: splitter(review[\"review_text\"]))).cache()\n",
    "\n",
    "# Do the inverse document frequency transform\n",
    "revIDF = IDF().fit(reviewFrequency)\n",
    "nor = Normalizer(p=2)\n",
    "features      = nor.transform(revIDF.transform(reviewFrequency)).cache()\n",
    "features_test = nor.transform(revIDF.transform(review_testFrequency)).cache()\n",
    "\n",
    "# Un-cache unneeded data sets\n",
    "reviewFrequency.unpersist()\n",
    "review_testFrequency.unpersist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Join the labels back with the features\n",
    "data = features.zip(labels).map(lambda (feature, label): LabeledPoint(label, feature)).cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b) The regression model and evaluation\n",
    "Write a function to compute MSE for training and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def treeMSE(tree,train_feat=features,train_label=labels,test_feat=features_test,test_label=labels_test,log=False):\n",
    "    '''\n",
    "    Evaluates training and test error for a pyspark mllib tree model\n",
    "    '''\n",
    "    if log:\n",
    "        train_MSE = train_label.zip(tree.predict(train_feat)).map(lambda (l,p):(l-np.log(p))**2).sum() / train_label.count()\n",
    "        test_MSE  = test_label.zip(tree.predict(test_feat)).map(lambda (l,p):(l-np.log(p))**2).sum() / test_label.count()\n",
    "    else:\n",
    "        train_MSE = train_label.zip(tree.predict(train_feat)).map(lambda (l,p):(l-p)**2).sum() / train_label.count()\n",
    "        test_MSE  = test_label.zip(tree.predict(test_feat)).map(lambda (l,p):(l-p)**2).sum() / test_label.count()\n",
    "    return(train_MSE,test_MSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####(c) train and test some trees\n",
    "First, random forrests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With 2 trees, got 0.0252 training error MSE and 0.0252 testing error\n"
     ]
    }
   ],
   "source": [
    "model=RandomForest.trainRegressor(data=data,categoricalFeaturesInfo={},numTrees=2,impurity='variance',maxDepth=4,maxBins=25)\n",
    "trerr,teerr = treeMSE(model)\n",
    "print 'With %d trees, got %.4f training error MSE and %.4f testing error' % (2,trerr,teerr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With 10 trees, got 0.0247 training error MSE and 0.0247 testing error\n",
      "With 25 trees, got 0.0246 training error MSE and 0.0246 testing error\n",
      "With 50 trees, got 0.0246 training error MSE and 0.0246 testing error\n",
      "With 100 trees, got 0.0246 training error MSE and 0.0246 testing error\n"
     ]
    }
   ],
   "source": [
    "# Try with max depth 4 and max bins 25\n",
    "# Suprisingly, I don't see a way to add additional trees to a random forrest once its initially fit, so I'm\n",
    "# averaging accross the forrests on my own to save computation\n",
    "marg_trees = [10,15,25,50]\n",
    "model_set1 = []\n",
    "ct=0\n",
    "for i in range(len(marg_trees)):\n",
    "    model_set1.append(RandomForest.trainRegressor(data=data,categoricalFeaturesInfo={},numTrees=marg_trees[i],impurity='variance',maxDepth=4,maxBins=25))\n",
    "    if i==0:\n",
    "        train_fit = labels.zip(model_set1[i].predict(features))\n",
    "        test_fit  = labels_test.zip(model_set1[i].predict(features_test))\n",
    "    else:\n",
    "        cw        =            ct/(ct+marg_trees[i])\n",
    "        mw        = marg_trees[i]/(ct+marg_trees[i])\n",
    "        train_fit = train_fit.zip(model_set1[i].predict(features)     ).map(lambda ((l,cp),mp): (l,cw*cp+mw*mp) )\n",
    "        test_fit  =  test_fit.zip(model_set1[i].predict(features_test)).map(lambda ((l,cp),mp): (l,cw*cp+mw*mp) )\n",
    "    ct += marg_trees[i]\n",
    "    # Training then test error\n",
    "    trerr = train_fit.map(lambda (l,p):(l-p)**2).sum()/train_fit.count()\n",
    "    teerr = test_fit.map(lambda (l,p):(l-p)**2).sum()/test_fit.count()\n",
    "    print 'With %d trees, got %.4f training error MSE and %.4f testing error' % (ct,trerr,teerr)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It doesn't seem to change much even after only 10 trees, probably because it's relatively shallow and on highly reduced data. Lets see if ramping up the complexity improves things. Also, the testing and training error only appear to be the same due to the rounding, they are actually different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0239 training error MSE and 0.0239 testing error\n"
     ]
    }
   ],
   "source": [
    "# Max depth 6, max bins 50, 25 trees\n",
    "model=RandomForest.trainRegressor(data=data,categoricalFeaturesInfo={},numTrees=25,impurity='variance',maxDepth=6,maxBins=50)\n",
    "trerr,teerr = treeMSE(model)\n",
    "print '%.4f training error MSE and %.4f testing error' % (trerr,teerr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now some gradient boosted trees. Start by looking out how error changes over number of iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With 10 iterations, got 0.0257 training error MSE and 0.0258 testing error\n",
      "With 50 iterations, got 0.0237 training error MSE and 0.0237 testing error\n",
      "With 100 iterations, got 0.0228 training error MSE and 0.0229 testing error\n"
     ]
    }
   ],
   "source": [
    "# Least squares loss, max depth of 1\n",
    "model_set2 = []\n",
    "for itnum in [10,50,100]:\n",
    "    model_set2.append(GradientBoostedTrees.trainRegressor(data=data,categoricalFeaturesInfo={},numIterations=itnum,loss='leastSquaresError',maxDepth=1))\n",
    "    trerr,teerr = treeMSE(model_set2[-1])\n",
    "    print 'With %d iterations, got %.4f training error MSE and %.4f testing error' % (itnum,trerr,teerr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0235 training error MSE and 0.0236 testing error\n"
     ]
    }
   ],
   "source": [
    "# max depth of 2, 25 iterations, still least square loss\n",
    "model=GradientBoostedTrees.trainRegressor(data=data,categoricalFeaturesInfo={},numIterations=25,loss='leastSquaresError',maxDepth=2)\n",
    "trerr,teerr = treeMSE(model)\n",
    "print '%.4f training error MSE and %.4f testing error' % (trerr,teerr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1660 training error MSE and 2.1668 testing error\n"
     ]
    }
   ],
   "source": [
    "# max depth of 1, 50 iterations, exponential loss\n",
    "model=GradientBoostedTrees.trainRegressor(data=data,categoricalFeaturesInfo={},numIterations=50,loss='logLoss',maxDepth=1)\n",
    "trerr,teerr = treeMSE(model)\n",
    "print '%.4f training error MSE and %.4f testing error' % (trerr,teerr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it turns out, if you one uses log loss, one has to take the log of the prediction. Go figure. Here is the actual training error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0368 training error MSE and 0.0370 testing error\n"
     ]
    }
   ],
   "source": [
    "trerr,teerr = treeMSE(model, log=True)\n",
    "print '%.4f training error MSE and %.4f testing error' % (trerr,teerr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
